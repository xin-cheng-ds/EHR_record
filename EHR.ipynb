{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a62e09a-b16a-47cf-bc2a-83a764a4f698",
      "metadata": {
        "id": "8a62e09a-b16a-47cf-bc2a-83a764a4f698",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "TIehMrYcjCwX",
      "metadata": {
        "id": "TIehMrYcjCwX"
      },
      "outputs": [],
      "source": [
        "#for colab reading files\n",
        "path = 'drive/My Drive/Projects/EHR_record/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vRN8rZYGjsmp",
      "metadata": {
        "id": "vRN8rZYGjsmp",
        "tags": []
      },
      "outputs": [],
      "source": [
        "path=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "G_32CmBHi56R",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_32CmBHi56R",
        "outputId": "67992d59-735e-4148-c71a-1e6ead7edd14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "160c1570-b05e-4bf8-a57c-f75d329e1ea3",
      "metadata": {
        "id": "160c1570-b05e-4bf8-a57c-f75d329e1ea3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "demographic_train = pd.read_csv(path+'Train/demographics.csv')\n",
        "labs_train = pd.read_csv(path+'Train/labs.csv')\n",
        "vitals_train = pd.read_csv(path+'Train/vitals.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0b1088e-b2aa-40e2-af67-14a4e419d25a",
      "metadata": {
        "id": "e0b1088e-b2aa-40e2-af67-14a4e419d25a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "demographic_test = pd.read_csv(path+'Test/demographics.csv')\n",
        "labs_test = pd.read_csv(path+'Test/labs.csv')\n",
        "vitals_test = pd.read_csv(path+'Test/vitals.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1455804d-bc93-4fbb-b5e2-c74e82b203d1",
      "metadata": {
        "id": "1455804d-bc93-4fbb-b5e2-c74e82b203d1"
      },
      "outputs": [],
      "source": [
        "demo_20 = demographic_train.sample(20).to_csv('demo.csv')\n",
        "lab_20 = labs_train.sample(20).to_csv('labs.csv')\n",
        "vital_20 = vitals_train.sample(20).to_csv('vitals.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "116c470f-6f60-4181-bb78-caa467b4b29d",
      "metadata": {
        "id": "116c470f-6f60-4181-bb78-caa467b4b29d"
      },
      "source": [
        "## 1. Exloratory analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6f58f201-095b-4c86-9701-daa89deb8158",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f58f201-095b-4c86-9701-daa89deb8158",
        "outputId": "58bc9cb9-f3a2-4336-c58e-bfe7d37ba2e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EDA for demographic:\n",
            "          patient_id   hospital_id  hospital_death           age  \\\n",
            "count   64384.000000  64384.000000    64384.000000  61263.000000   \n",
            "mean    65628.023003    104.891153        0.082179     62.475524   \n",
            "std     37789.609303     61.335116        0.274639     16.788310   \n",
            "min         1.000000      2.000000        0.000000     16.000000   \n",
            "25%     32967.750000     51.000000        0.000000     53.000000   \n",
            "50%     65571.500000    116.000000        0.000000     65.000000   \n",
            "75%     98343.750000    158.000000        0.000000     75.000000   \n",
            "max    131051.000000    204.000000        1.000000     89.000000   \n",
            "\n",
            "                bmi  elective_surgery        height        weight  \\\n",
            "count  61554.000000      64384.000000  63477.000000  62004.000000   \n",
            "mean      29.209720          0.185823    169.523406     83.984488   \n",
            "std        8.353251          0.388966     10.780263     25.227411   \n",
            "min       14.844926          0.000000    137.200000     38.600000   \n",
            "25%       23.625053          0.000000    162.500000     66.500000   \n",
            "50%       27.623893          0.000000    170.000000     80.055000   \n",
            "75%       32.966428          0.000000    177.800000     97.100000   \n",
            "max       67.814990          1.000000    195.590000    186.000000   \n",
            "\n",
            "             icu_id  pre_icu_los_days  ...  apache_icu_death_prob  \\\n",
            "count  64384.000000      64384.000000  ...           56718.000000   \n",
            "mean     476.380017          0.791365  ...               0.116627   \n",
            "std      235.456436          2.311556  ...               0.164958   \n",
            "min       82.000000        -24.947222  ...               0.000000   \n",
            "25%      317.000000          0.029861  ...               0.020000   \n",
            "50%      479.000000          0.123611  ...               0.050000   \n",
            "75%      678.000000          0.384028  ...               0.130000   \n",
            "max      926.000000         81.802778  ...               0.990000   \n",
            "\n",
            "         ventilated          aids     cirrhosis  diabetes_mellitus  \\\n",
            "count  63872.000000  63872.000000  63872.000000       63872.000000   \n",
            "mean       0.313768      0.000892      0.016721           0.229694   \n",
            "std        0.464027      0.029860      0.128225           0.420639   \n",
            "min        0.000000      0.000000      0.000000           0.000000   \n",
            "25%        0.000000      0.000000      0.000000           0.000000   \n",
            "50%        0.000000      0.000000      0.000000           0.000000   \n",
            "75%        1.000000      0.000000      0.000000           0.000000   \n",
            "max        1.000000      1.000000      1.000000           1.000000   \n",
            "\n",
            "       hepatic_failure  immunosuppression      leukemia      lymphoma  \\\n",
            "count     63872.000000       63872.000000  63872.000000  63872.000000   \n",
            "mean          0.013057           0.025504      0.006857      0.003930   \n",
            "std           0.113521           0.157652      0.082526      0.062565   \n",
            "min           0.000000           0.000000      0.000000      0.000000   \n",
            "25%           0.000000           0.000000      0.000000      0.000000   \n",
            "50%           0.000000           0.000000      0.000000      0.000000   \n",
            "75%           0.000000           0.000000      0.000000      0.000000   \n",
            "max           1.000000           1.000000      1.000000      1.000000   \n",
            "\n",
            "       solid_tumor_with_metastasis  \n",
            "count                 63872.000000  \n",
            "mean                      0.021120  \n",
            "std                       0.143787  \n",
            "min                       0.000000  \n",
            "25%                       0.000000  \n",
            "50%                       0.000000  \n",
            "75%                       0.000000  \n",
            "max                       1.000000  \n",
            "\n",
            "[8 rows x 22 columns]\n",
            "Size of demographic: (64384, 29)\n",
            "Null values in demographic:\n",
            " patient_id                         0\n",
            "hospital_id                        0\n",
            "hospital_death                     0\n",
            "age                             3121\n",
            "bmi                             2830\n",
            "elective_surgery                   0\n",
            "ethnicity                       1266\n",
            "gender                            15\n",
            "height                           907\n",
            "weight                          2380\n",
            "hospital_admit_source          15953\n",
            "icu_admit_source                  81\n",
            "icu_id                             0\n",
            "icu_stay_type                      0\n",
            "icu_type                           0\n",
            "pre_icu_los_days                   0\n",
            "readmission_status                 0\n",
            "bodysystem_diagnosis_admit      1150\n",
            "diagnosis_admit                  757\n",
            "apache_icu_death_prob           7666\n",
            "ventilated                       512\n",
            "aids                             512\n",
            "cirrhosis                        512\n",
            "diabetes_mellitus                512\n",
            "hepatic_failure                  512\n",
            "immunosuppression                512\n",
            "leukemia                         512\n",
            "lymphoma                         512\n",
            "solid_tumor_with_metastasis      512\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "EDA for labs:\n",
            "          patient_id      Min Value     Max Value\n",
            "count  759653.000000  759653.000000  759653.00000\n",
            "mean    65633.902142      54.742216      61.24596\n",
            "std     37742.813529      73.715720      84.05407\n",
            "min         1.000000       0.300000       0.33000\n",
            "25%     33071.000000       7.900000       8.20000\n",
            "50%     65609.000000      19.000000      21.00000\n",
            "75%     98190.000000      98.000000     118.00000\n",
            "max    131051.000000     670.000000     695.04500\n",
            "Size of labs: (759653, 6)\n",
            "Null values in labs:\n",
            " patient_id                                           0\n",
            "Lab                                                  0\n",
            "Min Value                                            0\n",
            "Max Value                                            0\n",
            "Unit of Measure                                      0\n",
            "Time of Measure (First Day or First Hour of Stay)    0\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "EDA for vitals:\n",
            "         patient_id     Min Value     Max Value\n",
            "count  1.237329e+06  1.237329e+06  1.237329e+06\n",
            "mean   6.563785e+04  6.980666e+01  9.067879e+01\n",
            "std    3.778164e+04  3.299414e+01  4.040548e+01\n",
            "min    1.000000e+00  0.000000e+00  0.000000e+00\n",
            "25%    3.299400e+04  4.500000e+01  6.600000e+01\n",
            "50%    6.562700e+04  7.000000e+01  9.500000e+01\n",
            "75%    9.833000e+04  9.300000e+01  1.130000e+02\n",
            "max    1.310510e+05  1.950000e+02  2.320000e+02\n",
            "Size of vitals: (1237329, 6)\n",
            "Null values in vitals:\n",
            " patient_id                                           0\n",
            "Vital                                                0\n",
            "Min Value                                            0\n",
            "Max Value                                            0\n",
            "Unit of Measure                                      0\n",
            "Time of Measure (First Day or First Hour of Stay)    0\n",
            "dtype: int64\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def perform_eda(dataframes, names):\n",
        "    for df, name in zip(dataframes, names):\n",
        "        print(f\"EDA for {name}:\")\n",
        "        print(df.describe())\n",
        "        print(f\"Size of {name}:\", df.shape)\n",
        "        print(f\"Null values in {name}:\\n\", df.isnull().sum())\n",
        "        print(\"\\n\")\n",
        "\n",
        "# Usage:\n",
        "dataframes = [demographic_train, labs_train, vitals_train]\n",
        "names = [\"demographic\", \"labs\", \"vitals\"]\n",
        "perform_eda(dataframes, names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fbb745a3-ec65-41ac-9650-9c78b4f6cbc0",
      "metadata": {
        "id": "fbb745a3-ec65-41ac-9650-9c78b4f6cbc0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define merge dataset function\n",
        "def merge_datasets(df1, df2, df3, key):\n",
        "\n",
        "    merged_df = pd.merge(df1, df2, on=key, how='inner')\n",
        "    merged_df = pd.merge(merged_df, df3, on=key, how='inner')\n",
        "    return merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "647c3936-7d2a-48aa-82f5-368d0d42059f",
      "metadata": {
        "id": "647c3936-7d2a-48aa-82f5-368d0d42059f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train = merge_datasets(demographic_train,vitals_train,labs_train,'patient_id')\n",
        "#test = merge_datasets(demographic_test,vitals_test,labs_test,'patient_id')\n",
        "y_train = train['hospital_death']\n",
        "X_train = train.drop('hospital_death', axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "866461eb-1a56-4ddc-b38c-50df88bc1329",
      "metadata": {
        "id": "866461eb-1a56-4ddc-b38c-50df88bc1329"
      },
      "source": [
        "## 2. Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "39cf26de-9dd9-4bc6-a24c-0d8cdeccfc83",
      "metadata": {
        "id": "39cf26de-9dd9-4bc6-a24c-0d8cdeccfc83",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08cacae8-f3c9-45b8-9261-fc1c07e9255a",
      "metadata": {
        "id": "08cacae8-f3c9-45b8-9261-fc1c07e9255a"
      },
      "source": [
        "3. Fit on models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c8889158-178a-429f-8e53-e52d1a229bb5",
      "metadata": {
        "id": "c8889158-178a-429f-8e53-e52d1a229bb5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#sampling data, straitify on the target column, also split group columns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class StratifiedGroupSampler:\n",
        "    def __init__(self, df, target_col, group_col, fraction, random_state=42):\n",
        "        self.df = df\n",
        "        self.target_col = target_col\n",
        "        self.group_col = group_col\n",
        "        self.fraction = fraction\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def sample(self):\n",
        "        sampled_df = pd.DataFrame()\n",
        "\n",
        "        for target in self.df[self.target_col].unique():\n",
        "            group_ids = self.df[self.df[self.target_col] == target][self.group_col].unique()\n",
        "            _, sampled_ids = train_test_split(group_ids, test_size=self.fraction, random_state=self.random_state)\n",
        "\n",
        "            sampled_data = self.df[self.df[self.group_col].isin(sampled_ids)]\n",
        "            sampled_df = pd.concat([sampled_df, sampled_data])\n",
        "\n",
        "        return sampled_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "873014e6-371e-49a0-b05d-4706aeac624c",
      "metadata": {
        "id": "873014e6-371e-49a0-b05d-4706aeac624c"
      },
      "outputs": [],
      "source": [
        "def sample_data(df, fraction):\n",
        "\n",
        "    sampler = StratifiedGroupSampler(df, 'hospital_death', 'patient_id', fraction)\n",
        "    sampled_train = sampler.sample()\n",
        "    X_sampled = sampled_train.drop('hospital_death', axis = 1)\n",
        "    y_sampled = sampled_train['hospital_death']\n",
        "\n",
        "\n",
        "    return X_sampled, y_sampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "935eea25-db90-4234-afa2-43f3cf8d294d",
      "metadata": {
        "id": "935eea25-db90-4234-afa2-43f3cf8d294d"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Logistic Regressy hyperparamerters\n",
        "logistic_params = {\n",
        "    'classifier__max_iter': [100, 500, 1000]\n",
        "}\n",
        "\n",
        "\n",
        "# Random Forest hyperparameters\n",
        "rf_params = {\n",
        "    'classifier__n_estimators': [100, 200, 300],\n",
        "    'classifier__max_depth': [10, 20, 30],\n",
        "    'classifier__min_samples_split': [2, 5, 10],\n",
        "    'classifier__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Gradient Boosting hyperparameters\n",
        "gb_params = {\n",
        "    'classifier__n_estimators': [100, 200, 300],\n",
        "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
        "    'classifier__max_depth': [3, 5, 7]\n",
        "}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jddkoC_Pe-xr",
        "outputId": "998ce377-cd7b-449d-e721-7bf3c529f9f3"
      },
      "id": "jddkoC_Pe-xr",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.6)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.32)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.29.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ee5179ec-5f87-4a7d-826b-57e5ee2cd78b",
      "metadata": {
        "id": "ee5179ec-5f87-4a7d-826b-57e5ee2cd78b"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f82f0970-9b29-41d6-a863-5a9f345af16e",
      "metadata": {
        "id": "f82f0970-9b29-41d6-a863-5a9f345af16e"
      },
      "outputs": [],
      "source": [
        "# Get numerical features\n",
        "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Get categorical features\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "\n",
        "# Define the preprocessing steps with all pipeline\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine numerical and categorical preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Define the pipelines to try\n",
        "pipelines = [\n",
        "    {\"name\": \"Logistic Regression\", \"pipeline\": Pipeline([('preprocessor', preprocessor),\n",
        "                                                          ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced'))]),\n",
        "                                                            \"params_grid\": {'classifier__max_iter': [100, 500, 1000]}},\n",
        "   {\"name\": \"Random Forest\", \"pipeline\": Pipeline([('preprocessor', preprocessor),\n",
        "                                                   ('classifier', RandomForestClassifier())]),\n",
        "                                                    \"params_grid\": rf_params},\n",
        "\n",
        "    {\"name\": \"Gradient Boost\", \"pipeline\": Pipeline([('preprocessor', preprocessor),\n",
        "                                                     ('classifier', GradientBoostingClassifier())]),\n",
        "                                                     \"params_grid\": gb_params},\n",
        "\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "89d0e66a-843b-4fc1-88c0-e03e516ecb41",
      "metadata": {
        "id": "89d0e66a-843b-4fc1-88c0-e03e516ecb41"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define the fractions to try\n",
        "fractions = [0.1, 0.2, 0.3]\n",
        "\n",
        "# Define scoring dictionary\n",
        "scoring = {\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'f1_score': 'f1'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "add66de6-8f74-4674-aada-54c2c990ecd5",
      "metadata": {
        "id": "add66de6-8f74-4674-aada-54c2c990ecd5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Helper function to fit the model with error handling\n",
        "def fit_model(pipeline_dict, X_train, y_train):\n",
        "    try:\n",
        "        random_search = RandomizedSearchCV(pipeline_dict['pipeline'], pipeline_dict.get('params_grid', {}),\n",
        "                                           n_iter=10, cv=5, scoring=scoring, refit=False, random_state=42)\n",
        "        random_search.fit(X_train, y_train)\n",
        "        return random_search\n",
        "    except Exception as e:\n",
        "        error_message = f\"An error occurred while fitting the model {pipeline_dict['name']}: {e}\"\n",
        "        print(error_message)\n",
        "        wandb.log({\"error\": error_message}) # Logging the error to W&B\n",
        "        return None\n",
        "\n",
        "# Helper function to evaluate the model with error handling\n",
        "def evaluate_model(random_search, X_val, y_val, model_name, fraction):\n",
        "    if random_search is None:\n",
        "        error_message = f\"Skipping evaluation for {model_name} due to an error during fitting.\"\n",
        "        print(error_message)\n",
        "        wandb.log({\"error\": error_message}) # Logging the error to W&B\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        y_pred = random_search.predict(X_val)\n",
        "        y_prob = random_search.predict_proba(X_val)[:, 1]\n",
        "        cm = confusion_matrix(y_val, y_pred)\n",
        "        fpr, tpr, _ = roc_curve(y_val, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        log_results(random_search, cm, fpr, tpr, roc_auc, model_name, fraction)\n",
        "    except Exception as e:\n",
        "        error_message = f\"An error occurred while evaluating the model {model_name}: {e}\"\n",
        "        print(error_message)\n",
        "        wandb.log({\"error\": error_message}) # Logging the error to W&B\n",
        "\n",
        "def log_results(random_search, cm, fpr, tpr, roc_auc, model_name, fraction):\n",
        "    \"\"\"Log results to W&B, including confusion matrix, ROC curve, and feature importances.\"\"\"\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title(f\"Confusion Matrix for {model_name} with fraction {fraction}\")\n",
        "    confusion_matrix_image = plt.gcf()\n",
        "    plt.close()\n",
        "\n",
        "    # Plot ROC curve\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(fpr, tpr, lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], lw=2, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve for {model_name} with fraction {fraction}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    roc_curve_image = plt.gcf()\n",
        "    plt.close()\n",
        "\n",
        "    # Log the results\n",
        "    wandb.log({\n",
        "        \"model_name\": model_name,\n",
        "        \"best_params\": random_search.best_params_,\n",
        "        \"best_score\": random_search.best_score_,\n",
        "        \"confusion_matrix\": wandb.Image(confusion_matrix_image),\n",
        "        \"roc_curve\": wandb.Image(roc_curve_image),\n",
        "        \"precision\": random_search.cv_results_['mean_test_precision'].mean(),\n",
        "        \"recall\": random_search.cv_results_['mean_test_recall'].mean(),\n",
        "        \"f1_score\": random_search.cv_results_['mean_test_f1_score'].mean(),\n",
        "        \"fraction\": fraction\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "aa98153a-abbd-4be5-b33a-0827f11fa83f",
      "metadata": {
        "id": "aa98153a-abbd-4be5-b33a-0827f11fa83f"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(pipelines, fractions, train_data):\n",
        "    # Initialize W&B\n",
        "    wandb.init(project=\"EHR_record\")\n",
        "\n",
        "    # Loop over the pipelines and fractions\n",
        "    for pipeline_dict in pipelines:\n",
        "        for fraction in fractions:\n",
        "            print(f\"Training {pipeline_dict['name']} with fraction {fraction}\")\n",
        "            X_sampled, y_sampled = sample_data(train_data, fraction)\n",
        "            X_train, X_val, y_train, y_val = train_test_split(X_sampled, y_sampled, test_size=0.2)\n",
        "\n",
        "            # Fit the model\n",
        "            random_search = fit_model(pipeline_dict, X_train, y_train)\n",
        "\n",
        "            # Evaluate the model\n",
        "            evaluate_model(random_search, X_val, y_val, pipeline_dict['name'], fraction)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d01f1d77-70ac-421e-a279-1313f2f43bb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d01f1d77-70ac-421e-a279-1313f2f43bb9",
        "outputId": "8862ff9c-1cb2-4e63-c65e-44f742c47829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxin0558\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230811_214537-5bnyqz0e</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/xin0558/EHR_record/runs/5bnyqz0e' target=\"_blank\">dainty-shadow-8</a></strong> to <a href='https://wandb.ai/xin0558/EHR_record' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/xin0558/EHR_record' target=\"_blank\">https://wandb.ai/xin0558/EHR_record</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/xin0558/EHR_record/runs/5bnyqz0e' target=\"_blank\">https://wandb.ai/xin0558/EHR_record/runs/5bnyqz0e</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression with fraction 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred while evaluating the model Logistic Regression: This RandomizedSearchCV instance was initialized with `refit=False`. predict is available only after refitting on the best parameters. You can refit an estimator manually using the `best_params_` attribute\n",
            "Training Logistic Regression with fraction 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Train and evaluate model\n",
        "train_and_evaluate(pipelines, fractions, train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nsrBuGhqhoYL"
      },
      "id": "nsrBuGhqhoYL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "data",
      "language": "python",
      "name": "data"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "toc-autonumbering": true
  },
  "nbformat": 4,
  "nbformat_minor": 5
}